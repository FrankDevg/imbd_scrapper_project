# ğŸ¬ IMDb Scraper â€“ Arquitectura Limpia para Scraping Distribuido y Persistencia HÃ­brida

Este proyecto es la soluciÃ³n integral a la prueba tÃ©cnica, demostrando la capacidad de construir un sistema de extracciÃ³n de datos robusto, escalable y mantenible. Se ha desarrollado un scraper para el Top 250 de IMDb, implementando tÃ©cnicas avanzadas de evasiÃ³n de bloqueos, persistencia en PostgreSQL y una arquitectura de software desacoplada, lista para evolucionar.

El diseÃ±o se fundamenta en principios de **Clean Architecture** y **Domain-Driven Design (DDD)**, estÃ¡ completamente **orquestado con Docker**, y documenta una estrategia clara para escalar hacia herramientas como Playwright o Selenium si las defensas del sitio objetivo lo requiriesen.

---
## ğŸ§­ Tabla de Contenido

- [âœ… Objetivos Cumplidos y Cobertura de Requisitos](#-objetivos-cumplidos-y-cobertura-de-requisitos)
- [ğŸ›ï¸ FilosofÃ­a de Arquitectura y Decisiones TÃ©cnicas](#ï¸-filosofÃ­a-de-arquitectura-y-decisiones-tÃ©cnicas)
- [ğŸ§± Estructura del Proyecto](#ï¸-estructura-del-proyecto)
- [ğŸ§© Estrategia de Red Distribuida: VPN + Proxies + TOR](#ï¸-estrategia-de-red-distribuida-vpn--proxies--tor)
- [ğŸ³ Instrucciones de Despliegue con Docker](#-instrucciones-de-despliegue-con-docker)
- [ğŸ§  SQL AnalÃ­tico](#-sql-analÃ­tico)
- [ğŸ•¸ï¸ ComparaciÃ³n TÃ©cnica â€“ Scrapy vs Playwright/Selenium](#ï¸-comparaciÃ³n-tÃ©cnica--scrapy-vs-playwrightselenium)
- [ğŸ§µ Concurrencia Aplicada en el Scraper](#-concurrencia-aplicada-en-el-scraper)
- [## ğŸ” Decisiones TÃ©cnicas Clave](#-decisiones-tÃ©cnicas-clave)
- [ğŸ“¦ Entregables Finales](#-entregables-finales)
- [ğŸ“£ CrÃ©ditos](#-crÃ©ditos)
---
## âœ… Objetivos Cumplidos y Cobertura de Requisitos

Se ha cumplido con el 100% de los requisitos solicitados, tanto obligatorios como opcionales, para demostrar una competencia exhaustiva en cada Ã¡rea evaluada.

| Ãrea de EvaluaciÃ³n | âœ… Implementado | Detalle TÃ©cnico de la ImplementaciÃ³n |
| :--- | :---: | :--- |
| **Scraping (60%)** | âœ… SÃ­ | Se extraen las 250 pelÃ­culas del chart, obteniendo TÃ­tulo, AÃ±o, CalificaciÃ³n, DuraciÃ³n, Metascore y Actores desde las pÃ¡ginas de detalle. La soluciÃ³n es modular y maneja errores con reintentos y backoff exponencial. |
| **Arquitectura Avanzada** | âœ… SÃ­ | Se implementÃ³ **Clean Architecture + DDD** y el patrÃ³n **Factory** para desacoplar la lÃ³gica de negocio de la infraestructura (ej. persistencia, scraping). |
| **Persistencia CSV + SQL** | âœ… SÃ­ | Los datos se persisten de forma hÃ­brida en archivos CSV y en un esquema relacional PostgreSQL con una relaciÃ³n `N:M` entre pelÃ­culas y actores. |
| **SQL AnalÃ­tico (20%)** | âœ… SÃ­ | Se crearon consultas analÃ­ticas complejas utilizando **funciones de ventana (`OVER/PARTITION BY`)**, vistas, Ã­ndices y justificaciÃ³n de particionamiento. |
| **Proxies y Red (10%)** | âœ… SÃ­ | Se implementÃ³ una arquitectura distribuida con mÃºltiples capas de evasiÃ³n: conexiÃ³n mediante **VPN real (ProtonVPN vÃ­a Docker)**, uso de **proxies premium (DataImpulse)** y fallback automÃ¡tico a la **red TOR**. AdemÃ¡s, se incluyÃ³ un sistema de **reintentos con backoff exponencial** y validaciÃ³n de IP para garantizar la obtenciÃ³n del dato. |
| **Dockerizado y Portable** | âœ… SÃ­ | Todo el entorno (scraper, base de datos) se levanta con un solo comando (`docker-compose up`), garantizando la replicabilidad del entorno. |
| **ComparaciÃ³n Herramientas (10%)** | âœ… SÃ­ | Se incluye una secciÃ³n detallada justificando cuÃ¡ndo y cÃ³mo migrar a **Playwright/Selenium** para escenarios de JavaScript dinÃ¡mico y CAPTCHAs. |
| **Evidencia y DocumentaciÃ³n** | âœ… SÃ­ | El repositorio incluye logs, scripts SQL, CSVs generados y este README detallado como evidencia del trabajo realizado. |

---

## ğŸ›ï¸ FilosofÃ­a de Arquitectura y Decisiones TÃ©cnicas

### Â¿Por quÃ© Clean Architecture + Domain-Driven Design (DDD)?
Un enfoque profesional exige construir un **sistema mantenible y escalable**.

- **SeparaciÃ³n de Responsabilidades (SoC):** Las dependencias apuntan hacia adentro. La lÃ³gica de negocio no sabe nada sobre la base de datos ni el scraping.
- **Testabilidad Aislada:** Las capas `domain` y `application` se pueden testear unitariamente sin dependencias externas.
- **Modelado del Dominio:** Entidades como `Movie` y `Actor` reflejan el lenguaje del problema, con validaciones integradas.

### Â¿Por quÃ© el PatrÃ³n Factory?
Se utiliza para desacoplar la lÃ³gica de negocio de las implementaciones concretas.

- Permite cambiar la fuente de persistencia (CSV, PostgreSQL, MongoDB) sin modificar la lÃ³gica del caso de uso.
- Cumple con el Principio Abierto/Cerrado.

### Â¿Por quÃ© TOR para la RotaciÃ³n de IPs?
TOR ofrece:

- **RotaciÃ³n efectiva de IPs** sin costo adicional.
- **Independencia del proveedor:** Se puede sustituir fÃ¡cilmente por otros proxies comerciales o VPNs.

---

## ğŸ§± Estructura del Proyecto

```
imbd_scraper_project/
â”œâ”€â”€ application/                  # Casos de uso orquestando lÃ³gica de dominio
â”‚   â””â”€â”€ use_cases/
â”‚       â”œâ”€â”€ composite_save_movie_with_actors_use_case.py
â”‚       â”œâ”€â”€ save_movie_with_actors_csv_use_case.py
â”‚       â”œâ”€â”€ save_movie_with_actors_postgres_use_case.py
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/                         # Archivos CSV generados automÃ¡ticamente
â”‚   â”œâ”€â”€ actors.csv
â”‚   â”œâ”€â”€ movies.csv
â”‚   â””â”€â”€ movie_actor.csv
â”‚
â”œâ”€â”€ domain/                       # Modelos, interfaces y contratos de repositorio
â”‚   â”œâ”€â”€ interfaces/               # Interfaces de scraper, proxy, etc.
â”‚   â”‚   â”œâ”€â”€ proxy_interface.py
â”‚   â”‚   â”œâ”€â”€ scraper_interface.py
â”‚   â”‚   â”œâ”€â”€ tor_interface.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/                   # Entidades del dominio
â”‚   â”‚   â”œâ”€â”€ actor.py
â”‚   â”‚   â”œâ”€â”€ movie.py
â”‚   â”‚   â”œâ”€â”€ movie_actor.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ repositories/            # Contratos de repositorios
â”‚       â”œâ”€â”€ actor_repository.py
â”‚       â”œâ”€â”€ movie_actor_repository.py
â”‚       â”œâ”€â”€ movie_repository.py
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ infrastructure/              # Implementaciones tecnolÃ³gicas
â”‚   â”œâ”€â”€ factory/                 # Factories para desacoplar la creaciÃ³n de objetos
â”‚   â”‚   â”œâ”€â”€ db_factory.py
â”‚   â”‚   â”œâ”€â”€ proxy_factory.py
â”‚   â”‚   â”œâ”€â”€ scraper_factory.py
â”‚   â”‚   â”œâ”€â”€ tor_factory.py
â”‚   â”‚   â”œâ”€â”€ use_case_factory.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ persistence/             # Implementaciones concretas de persistencia
â”‚   â”‚   â”œâ”€â”€ csv/
â”‚   â”‚   â”‚   â”œâ”€â”€ init_csv_files.py
â”‚   â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚   â”‚       â”œâ”€â”€ actor_csv_repository.py
â”‚   â”‚   â”‚       â”œâ”€â”€ movie_actor_csv_repository.py
â”‚   â”‚   â”‚       â””â”€â”€ movie_csv_repository.py
â”‚   â”‚   â””â”€â”€ postgres/
â”‚   â”‚       â”œâ”€â”€ postgres_connection.py
â”‚   â”‚       â””â”€â”€ repositories/
â”‚   â”‚           â”œâ”€â”€ actor_postgres_repository.py
â”‚   â”‚           â”œâ”€â”€ movie_actor_postgres_repository.py
â”‚   â”‚           â””â”€â”€ movie_postgres_repository.py
â”‚   â”œâ”€â”€ proxy_rotation/          # LÃ³gica de rotaciÃ³n TOR
â”‚   â”‚   â””â”€â”€ tor_rotator.py
â”‚   â”œâ”€â”€ provider/                # LÃ³gica de selecciÃ³n de proxy (ej. TOR, otros)
â”‚   â”‚   â””â”€â”€ proxy_provider.py
â”‚   â””â”€â”€ scraper/                 # ImplementaciÃ³n del scraper principal
â”‚       â”œâ”€â”€ imdb_scraper.py
â”‚       â”œâ”€â”€ utils.py
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ logs/                        # Archivos de logs del scraper
â”‚   â””â”€â”€ scraper.log
â”‚
â”œâ”€â”€ presentation/                # CLI o interfaces externas
â”‚   â””â”€â”€ cli/
â”‚       â”œâ”€â”€ run_scraper.py       # Punto de entrada principal
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ shared/                      # Utilidades globales
â”‚   â”œâ”€â”€ config/                  # Configuraciones centralizadas
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ logger/                  # ConfiguraciÃ³n de logging
â”‚       â””â”€â”€ logging_config.py
â”‚
â”œâ”€â”€ sql/                         # Scripts SQL para DB
â”‚   â”œâ”€â”€ 01_schema.sql
â”‚   â”œâ”€â”€ 02_procedures.sql
â”‚   â”œâ”€â”€ 03_views.sql
â”‚   â”œâ”€â”€ load_from_csv.sql
â”‚   â””â”€â”€ queries.sql
â”‚
â”œâ”€â”€ .env                         # Configuraciones de entorno (no versionar)
â”œâ”€â”€ .gitignore                   # Ignora .env, __pycache__, etc.
â”œâ”€â”€ docker-compose.yml           # OrquestaciÃ³n del proyecto con PostgreSQL
â”œâ”€â”€ Dockerfile                   # Imagen del scraper
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â””â”€â”€ README.md                    # DocumentaciÃ³n completa del sistema
```
---

### ğŸ§© Estrategia de Red Distribuida: VPN + Proxies + TOR

El scraper estÃ¡ preparado para ejecutar en ambientes con **alta sensibilidad al bloqueo**, usando una combinaciÃ³n de estrategias en capas para garantizar la recolecciÃ³n de datos:

| TecnologÃ­a        | PropÃ³sito                                    | ImplementaciÃ³n                                                      |
|------------------|----------------------------------------------|----------------------------------------------------------------------|
| **VPN (ProtonVPN)**     | Cambiar geolocalizaciÃ³n y evitar bloqueo regional | Montada en **Docker**, validaciÃ³n de paÃ­s vÃ­a healthcheck por imagen qmcgaw/gluetun            |
| **Proxies Premium**     | IPs rotativas anÃ³nimas, baja latencia            | IntegraciÃ³n con **DataImpulse**, rotaciÃ³n automÃ¡tica por cada request |
| **TOR (Fallback)**      | Red distribuida anÃ³nima gratuita                 | ActivaciÃ³n automÃ¡tica en caso de fallo en las otras capas            |

AdemÃ¡s, se integrÃ³ un **sistema de reintentos inteligentes con backoff exponencial** que asegura que la peticiÃ³n se repita en caso de fallo, cambiando IP si es necesario, y dejando trazabilidad en logs con la IP usada.

---

### ğŸ”§ Posibles Mejoras Futuras

- **Proxy Pool DinÃ¡mico** con rotaciÃ³n basada en reputaciÃ³n/IP-bans.
- **Auto-restart de TOR/VPN** si el healthcheck falla.
- IntegraciÃ³n con **servicios anti-CAPTCHA** como 2Captcha o Anti-Captcha.
- Compatibilidad con **geolocalizaciÃ³n dinÃ¡mica por paÃ­s**, seleccionando el proxy o VPN mÃ¡s adecuado segÃºn el sitio.

---

## ğŸ³ Instrucciones de Despliegue con Docker

1. Crear el archivo `.env` en la carpeta raiz  
### ğŸ“„ Archivo `.env` (proporcionado solo con fines de evaluaciÃ³n)

Este archivo contiene la configuraciÃ³n necesaria para conectar con los servicios de base de datos, proxies y VPN utilizados en el entorno del scraper.

**âš ï¸ Importante:** Las credenciales contenidas en este archivo son simuladas y han sido incluidas Ãºnicamente para facilitar la evaluaciÃ³n del proyecto. En un entorno real, se recomienda gestionar estas variables de forma segura mediante servicios como Docker Secrets, AWS Parameter Store o `.env` ignorado por `.gitignore`.

Ejemplo de `.env`:

```env

POSTGRES_DB=imdb_scraper
POSTGRES_USER=aruiz
POSTGRES_PASSWORD=@ndresruiz@123
POSTGRES_PORT=5432
POSTGRES_HOST=postgres


PROXY_HOST=gw.dataimpulse.com
PROXY_PORT=823
PROXY_USER=f1bdc8e207aafe131216
PROXY_PASS=6c1b9cdd85f65f0b

VPN_PROVIDER=protonvpn
VPN_USERNAME=qlT5gZGnlHi2Y1uh
VPN_PASSWORD=mUiXGzoM9SeYHhYocElsEMuQwUUGuLFL
VPN_COUNTRY=Argentina

```
2. Ejecutar:
   
```bash
docker-compose build --no-cache
```

```bash
docker-compose up
```

- PostgreSQL expuesto en `localhost:5432`.
- Scraper inicia automÃ¡ticamente.
- Logs en `logs/scraper.log`.
- Archivos `movies.csv`, `actors.csv`, `movie_actor.csv` generados en `/data`.

---

## ğŸ§  SQL AnalÃ­tico

Incluye:

- ğŸï¸ **Top 5 por duraciÃ³n promedio por dÃ©cada** â€“ con `ROW_NUMBER()` y `PARTITION BY`.
- ğŸ“ˆ **DesviaciÃ³n estÃ¡ndar de calificaciÃ³n por aÃ±o** â€“ mide dispersiÃ³n de opiniones.
- âš–ï¸ **ComparaciÃ³n IMDb vs Metascore** â€“ normalizado y filtrado por delta > 20%.
- ğŸ‘¥ **Vista Actor-PelÃ­cula** â€“ facilita filtrado y joins.
- âš¡ **Ãndices y vistas materializadas** â€“ optimizaciÃ³n de rendimiento.

---

## 4ï¸âƒ£ ComparaciÃ³n TÃ©cnica: Selenium o Playwright

Aunque este proyecto estÃ¡ construido con `requests` y `BeautifulSoup` por su requerimiento y control detallado del flujo, estÃ¡ preparado para escalar hacia herramientas como **Playwright** o **Selenium** en los siguientes escenarios:

### ğŸ”§ ConfiguraciÃ³n avanzada del navegador
- **Modo headless** configurable (visible/invisible).
- ModificaciÃ³n de **headers dinÃ¡micos** (User-Agent, Referer, etc.).
- **EvasiÃ³n de detecciÃ³n WebDriver** mediante tÃ©cnicas como redefinir `navigator.webdriver` o usar extensiones anti-bot.

### ğŸ¯ Selectores dinÃ¡micos con espera explÃ­cita
- Uso de `wait_for_selector` en Playwright o `WebDriverWait` con `expected_conditions` en Selenium.
- Evita errores por contenido cargado asincrÃ³nicamente.

### ğŸ›¡ï¸ Manejo de JavaScript y CAPTCHAs
- Renderizado completo del DOM con JS habilitado.
- DetecciÃ³n y resoluciÃ³n de CAPTCHAs mediante integraciÃ³n con servicios externos como **2Captcha**, **AntiCaptcha**, o estrategias por OCR.

### âš™ï¸ Control de concurrencia
- Playwright: mÃºltiples **browser contexts** en paralelo.
- Selenium: ejecuciÃ³n distribuida con **Selenium Grid** o containers aislados por worker.
- Posibilidad de usar **colas de scraping (ej. Celery, RabbitMQ)** para tareas distribuidas.

### ğŸ“Œ JustificaciÃ³n de uso
Estas herramientas deben considerarse cuando:
- IMDb o el sitio objetivo usa JavaScript para cargar datos clave.
- Se presentan mecanismos de bloqueo activo (CAPTCHA, WAF).
- Se desea simular comportamiento humano real (scroll, clics, etc.).

En este proyecto no fueron necesarias porque IMDb expone los datos principales vÃ­a HTML y GraphQL, pero se documenta cÃ³mo escalar si cambia el comportamiento del sitio.

---

## ğŸ§µ Concurrencia Aplicada en el Scraper

El scraper utiliza **`ThreadPoolExecutor`** desde la librerÃ­a `concurrent.futures` para acelerar la recolecciÃ³n de informaciÃ³n de detalle por pelÃ­cula.

### ğŸ§  Detalles tÃ©cnicos:
- Se limita el nÃºmero de threads para evitar saturar la red o el endpoint.
- Cada hilo ejecuta la funciÃ³n de extracciÃ³n del detalle de la pelÃ­cula (`/title/{id}/`) en paralelo.
- Esto mejora el rendimiento sin comprometer la trazabilidad ni la estructura del log.

Se podrÃ­an reemplazar por workers distribuidos en producciÃ³n para escalar horizontalmente.

---

## ğŸ” Decisiones TÃ©cnicas Clave

### ğŸ§  1. SQL Directo en lugar de ORM
DecidÃ­ **no utilizar un ORM como SQLAlchemy** y optar por sentencias SQL explÃ­citas, basÃ¡ndome en:

- âœ… **Simplicidad del modelo de datos** (pelÃ­culas, actores y relaciÃ³n N:M).
- âœ… **Mayor control sobre las operaciones** de escritura, validaciones y consultas analÃ­ticas.
- âœ… **SeparaciÃ³n limpia por repositorios**, que permite desacoplar la lÃ³gica de persistencia y facilitar una futura migraciÃ³n a un ORM sin modificar los casos de uso.
- âœ… **Mejor rendimiento para scraping masivo**, al evitar capas adicionales de abstracciÃ³n.

> Esta decisiÃ³n no limita la escalabilidad futura, ya que el diseÃ±o permite incorporar ORM cuando sea necesario.

---

### ğŸŒ 2. Scraping distribuido con rotaciÃ³n de IPs y red privada

Para garantizar robustez y anonimato en la extracciÃ³n de datos, el scraper estÃ¡ configurado con:

- ğŸ§… **Red TOR** activa para rotaciÃ³n bÃ¡sica de IPs.
- ğŸ”„ **User-Agent aleatorios y headers realistas** en cada solicitud.
- ğŸ§° **Proxies premium de Data Impulso**, integrados con fallback automÃ¡tico.
- ğŸ” **VPN real instalada dentro de Docker**, conectada a la red interna.
- ğŸ’£ Tolerancia a fallos mediante reintentos automÃ¡ticos y separaciÃ³n del canal de scraping y persistencia.

---

### ğŸ—‚ï¸ 3. Persistencia hÃ­brida (CSV + PostgreSQL)

Para garantizar versatilidad en el anÃ¡lisis y almacenamiento:

- ğŸ§¾ **CSV**: ExportaciÃ³n directa a `movies.csv`, `actors.csv` y `movie_actor.csv`, Ãºtil para revisiÃ³n rÃ¡pida o carga en herramientas externas.
- ğŸ›¢ï¸ **PostgreSQL**: Almacenamiento estructurado de pelÃ­culas, actores y relaciones, ideal para anÃ¡lisis SQL avanzado y consultas cruzadas.
- ğŸ§± Cada mecanismo de persistencia se implementÃ³ como un repositorio independiente bajo el patrÃ³n Strategy, permitiendo su uso simultÃ¡neo o alternativo.

---

### ğŸ§¼ 4. Arquitectura Limpia (Clean Architecture + DDD)

Todo el proyecto fue estructurado en capas bien definidas:

- `domain/`: Modelos de negocio y contratos de repositorios (interfaces).
- `application/`: Casos de uso desacoplados.
- `infrastructure/`: Implementaciones concretas (scraper, CSV, DB).
- `presentation/`: Punto de entrada (`run_scraper.py`).
- `shared/`: ConfiguraciÃ³n, logging y constantes.

> Esta estructura facilita pruebas unitarias, extensibilidad y mantenimiento a largo plazo.

---

### ğŸ‹ 5. Entorno Dockerizado con Red Privada Segura

El entorno de ejecuciÃ³n estÃ¡ totalmente containerizado y preparado para producciÃ³n:

- `docker-compose.yml` levanta servicios clave:
  - Scraper
  - PostgreSQL
  - Red TOR
  - **VPN montada en la red interna**
- Se utilizaron:
  - âœ… **Redes internas de Docker**
  - âœ… **VolÃºmenes persistentes**
  - âœ… **Variables externas (.env)**
- Se integraron **healthchecks propios de cada imagen Docker** para garantizar estabilidad de los servicios antes de ejecutar el scraping.
---
## ğŸ“¦ Entregables Finales

- ğŸ—ƒï¸ CÃ³digo en GitHub
- ğŸ˜ Scripts SQL en `/sql/`
- ğŸ“„ CSVs generados en `/data/`
- ğŸ§¾ Logs con rotaciÃ³n IP en `/logs/`
- ğŸ“˜ DocumentaciÃ³n tÃ©cnica (este archivo) y Documento de arquitectura `/docs/`

---

## ğŸ“£ CrÃ©ditos

Proyecto desarrollado por **AndrÃ©s Ruiz** para la prueba tÃ©cnica de Scraping Senior.  
ğŸ“« Email: franklindbruiz@gmail.com  
ğŸ”— GitHub: [frankdevg](https://github.com/frankdevg)
